---
title: "Homework 5"
output: pdf_document
date: "2025-10-02"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# [Question 9.1]{.underline}

> Using the same crime data set uscrime.txt as in Question 8.2
> <http://www.statsci.org/data/general/uscrime.txt> (file uscrime.txt,
> description at <http://www.statsci.org/data/general/uscrime.html> ),
> apply Principal Component Analysis and then create a regression model
> using the first few principal components. Specify your new model in
> terms of the original variables (not the principal components), and
> compare its quality to that of your solution to Question 8.2. You can
> use the R function `prcomp` for PCA. (Note that to first scale the
> data, you can include scale. = TRUE to scale as part of the PCA
> function. Don’t forget that, to make a prediction for the new city,
> you’ll need to unscale the coefficients (i.e., do the scaling
> calculation in reverse)!) Predict the observed crime_stats rate in a
> city with the following data:
>
> |               |               |                 |
> |:-------------:|:-------------:|:---------------:|
> |  `M = 14.0`   |   `So = 0`    |   `Ed = 10.0`   |
> | `Po1 = 12.0`  | `Po2 = 15.5`  |  `LF = 0.640`   |
> | `M.F = 94.0`  |  `Pop = 150`  |   `NW = 1.1`    |
> | `U1 = 0.120`  |  `U2 = 3.6`   | `Wealth = 3200` |
> | `Ineq = 20.1` | `Prob = 0.04` |  `Time = 39.0`  |
>
> Show your model (factors used and their coefficients), the software
> output, and the quality of fit.
>
> Note that because there are only 47 data points and 15 predictors,
> you’ll probably notice some overfitting. We’ll see ways of dealing
> with this sort of problem later in the course.

First, we load the necessary libraries:

```{r, message=FALSE}
library(printr)     # pretty print for Rmd
library(lubridate)  # dates
library(ggplot2)    # plots
library(dplyr)      # dataframes
library(tidyr)
library(tidyverse)
library(recipes)
library(caret)
library(MASS)      # step models

# set seed for reproducibility
set.seed(42)
```

Now let's load the data:

```{r}
df <- read.table("./data 8.2/uscrime.txt", header =TRUE)
```

Note: As was stated in the question, our data set is extremely limited,
therefore I will do 10-fold cross validation on the final model, but am
not going to be creating a final test set.

## Comparison to Homework 5

From Homework 5, my best model on all the training data had an adjusted
$R^2$ of 0.8514 and in 10-fold cross validation had $R^2$ of 0.7953447,
so those are the baselines I will be evaluating against. I am going to
add the same features as I used previously.

```{r}
crime_stats <- df
crime_stats$LF2 = crime_stats$LF^2
crime_stats$NW2 = crime_stats$NW^2
crime_stats$InvProb = 1 / crime_stats$Prob
```

## PCA

Now that we have the same set of features, let's do PCA

```{r}
pcs <- prcomp( subset(crime_stats, select=-c(Crime)) , scale = TRUE)
Xp <- as.data.frame(pcs$x)
Xp$Crime <- df$Crime

plot(pcs)
```

\newpage

By the sixth principal component a large amount of our variance has been
removed. Let's train a model on those and see what our prediction looks
like.

```{r}
lm_pc1_to_6 <- lm(Crime ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6, data=Xp)
summary(lm_pc1_to_6)

lm_pc1_to_6_log <- lm(log(Crime) ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6, data=Xp)
print(
  paste(
    "ln(Crime) model adjusted R^2:", summary(lm_pc1_to_6_log)$adj.r.squared
  )
)
```

Both the model against linear and log crime stats did significantly
worse! Although we can see that the terms all show some significance
showing that we are getting information out of the model.

\newpage

## Step AIC

Rather than relying on the transformed coefficients to select features,
I am going to use them to concentrate information and use Stepwise model
training to produce a parsimonious model.

Note: I also tested the linear model for this and the log version
performed better, so I am not going to continue to run them both.

```{r}
constant_model <- lm(log(Crime) ~ 1, data = Xp)
full_model <- lm(log(Crime) ~ ., data = Xp)

# pages of output
invisible(
  capture.output(
    step_model <- stepAIC(
      constant_model,
      scope = list(lower = constant_model, upper = full_model),
      direction = "both"
    )
  )
)

summary(step_model)
```

Interestingly all the terms are significant (unlike my model from
Homework 5), and the adjusted $R^2$ is a bit higher! Looking at the
magnitudes of the coefficients PC1, PC3, and PC8 I would have expected
them to be relatively unimportant; however, removing them caused a large
degredation in quality of fit.

\newpage

## Cross-validation

Now before transforming our coefficients back to true space. let's do
cross validation on the PC model.

```{r}
train_control <- trainControl(method = "cv", number = 10)
cross_val_stats <- train(
  formula(step_model),
  data = Xp,
  method = "lm",
  trControl = train_control
)

cross_val_stats
```

I did not know that $R^2$ could be higher while MAE and RMSE were also
higher. I am not finding a clear explanation of this and will get
clarification. However, some of the resources I am seeing state that the
RMSE and MAE are more reliable metrics suggesting that the model is
worse.

\newpage

## Datapoint prediction

Let's see what the predicted crime_stats for the specified parameters is

```{r}
crime_test <- data.frame(
  M      = 14.0, So     = 0, Ed     = 10.0, Po1    = 12.0,
  Po2    = 15.5, LF     = 0.640, M.F    = 94.0, Pop    = 150,
  NW     = 1.1, U1     = 0.120, U2     = 3.6, Wealth = 3200,
  Ineq   = 20.1, Prob   = 0.04, Time   = 39.0
) %>% mutate(
  InvProb = 1 / Prob,
  LF2 = LF^2,
  NW2 = NW^2
)

crime_test_scaled <- as.data.frame(predict(pcs, crime_test))

# reverse the log scaling because for some reason that's not done automatically
exp(predict(step_model, crime_test_scaled))
```

This is significantly higher than the result from Homework 5 (490.4742).
I am very curious which model was better and wish we had a large enough
dataset to split out a test set.

\newpage

## Conversion to original space

Finally, let's transform our coefficients back from PC space to our
original space. The full conversion (including scaling and centering)
is[^1]. However, we need to limit to just the coefficients in our model.

[^1]: <https://stackoverflow.com/a/29784476/1543042>

```{r}
pc_space_intercept <- step_model$coefficients[1]
coefficients <- step_model$coefficients[-1] # exclude intercept
components <- names(coefficients)

scaled_coefficients <- ((1/pcs$scale) * t(pcs$rotation[,components] %*% coefficients))
```

We also need to account for centering, I am personally thinking of this
as converting from the point-slope form of a line to the point-intercept
form. That means that to get our intercept in the original space we add
the intercept in PC space to the scaled coefficients times the negative
centers

```{r}
point_contribution_to_intercept <- -sum(scaled_coefficients * pcs$center)
original_space_intercept <- pc_space_intercept + point_contribution_to_intercept
```

Therefore our equation is

```{r results='asis'}
eq <- paste0(
  "log(Crime) = ",
  signif(original_space_intercept, digits=4),
  " + ",
  paste0(
    signif(scaled_coefficients, digits=4),
    " * ",
    colnames(scaled_coefficients), collapse = " + "
  )
)

eq <- gsub("\\+ -", "- ", eq)

cat(strwrap(eq, width = 80), sep = "\n")
```

```{r results='asis'}

```

\newpage

## Comparison and conclusions

Below I show both the coefficients from the PCA model as well as the
coefficients from an equivilent procedure from Homework 5 (although I
did not display unscalled coefficients and so needed to generate a like
comparison). As would be expected given the model has predictive value,
the coefficients of the common terms are within a factor of 2; although
I am actually surprised they diverged as much as they do. I would
suspect that given how poorly the raw PCA model performed and that
StepAIC pulled in down to PC18, that this problem is not actually well
suited for PCA and the StepAIC was attempting to approximate the non-PCA
version.

| Variable | PCA        | HW5        | PCA/HW5 |
|----------|------------|------------|---------|
| So       | 2.764E-02  | -1.501E-01 | -0.18   |
| NW       | 5.369E-02  | 6.802E-02  | 0.79    |
| Wealth   | 9.418E-05  | 1.169E-04  | 0.81    |
| Ed       | 2.135E-01  | 2.594E-01  | 0.82    |
| NW2      | -1.285E-03 | -1.551E-03 | 0.83    |
| U2       | 6.541E-02  | 7.853E-02  | 0.83    |
| Ineq     | 8.000E-02  | 8.282E-02  | 0.97    |
| InvProb  | 6.471E-03  | 6.489E-03  | 1.00    |
| M        | 1.015E-01  | 7.679E-02  | 1.32    |
| Pop      | -2.515E-03 | -1.833E-03 | 1.37    |
| Po1      | 1.217E-01  | 7.009E-02  | 1.74    |
| Po2      | -3.115E-02 | \-         | \-      |
| LF       | 4.895E+01  | \-         | \-      |
| M.F      | -3.443E-02 | \-         | \-      |
| U1       | 4.714E+00  | \-         | \-      |
| Prob     | -1.082E+00 | \-         | \-      |
| Time     | -5.965E-03 | \-         | \-      |
| LF2      | -4.069E+01 | \-         | \-      |

```{r}
library(Metrics)

crime_preds <- exp(predict(step_model, Xp))

data.frame(obs = crime_stats$Crime, pred = crime_preds) %>%
  summarise(
    Rsquared = R2(pred, obs),
    RMSE = RMSE(pred, obs),
    MAE = MAE(pred, obs)
  )
```
